{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "311cd81c-6356-4e0b-9dad-fb00c81ed8cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "user_df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/varshinie.1006@gmail.com/user_dim.csv\", header=True, inferSchema=True)\n",
    "transaction_df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/varshinie.1006@gmail.com/transaction_fact.csv\", header=True, inferSchema=True)\n",
    "fraud_df = spark.read.csv(\"dbfs:/FileStore/shared_uploads/varshinie.1006@gmail.com/fraud_indicators.csv\", header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab167f46-de15-42fa-b4a2-9d16f2754d50",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+--------------+--------+------------------+\n",
      "|summary|    transaction_id|           user_id|transaction_amount|payment_method|location|       fraud_label|\n",
      "+-------+------------------+------------------+------------------+--------------+--------+------------------+\n",
      "|  count|                10|                10|                10|            10|      10|                10|\n",
      "|   mean|             105.5|               3.0|           850.125|          null|    null|               0.2|\n",
      "| stddev|3.0276503540974917|1.4907119849998596| 931.2506916477671|          null|    null|0.4216370213557839|\n",
      "|    min|               101|                 1|              50.0|   Credit Card| Chicago|                 0|\n",
      "|    max|               110|                 5|            3000.0|        PayPal| Phoenix|                 1|\n",
      "+-------+------------------+------------------+------------------+--------------+--------+------------------+\n",
      "\n",
      "+-----------+-----+\n",
      "|fraud_label|count|\n",
      "+-----------+-----+\n",
      "|          1|    2|\n",
      "|          0|    8|\n",
      "+-----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#EDA\n",
    "transaction_df.describe().show()\n",
    "transaction_df.groupBy(\"fraud_label\").count().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1111a977-b5e6-47b1-bfee-66194f9f369c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------------------+\n",
      "|user_id|transaction_frequency|\n",
      "+-------+---------------------+\n",
      "|      1|                    2|\n",
      "|      3|                    2|\n",
      "|      5|                    2|\n",
      "|      4|                    2|\n",
      "|      2|                    2|\n",
      "+-------+---------------------+\n",
      "\n",
      "+-------+----------------------+\n",
      "|user_id|avg_transaction_amount|\n",
      "+-------+----------------------+\n",
      "|      1|                 975.0|\n",
      "|      3|                 575.0|\n",
      "|      5|                1525.0|\n",
      "|      4|               1000.25|\n",
      "|      2|               175.375|\n",
      "+-------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Feature Engineering\n",
    "freq_df = transaction_df.groupBy(\"user_id\").count().withColumnRenamed(\"count\", \"transaction_frequency\")\n",
    "freq_df.show()\n",
    "\n",
    "from pyspark.sql.functions import avg,unix_timestamp\n",
    "\n",
    "avg_amount_df = transaction_df.groupBy(\"user_id\").agg(avg(\"transaction_amount\").alias(\"avg_transaction_amount\"))\n",
    "avg_amount_df.show()\n",
    "\n",
    "user_df = user_df.withColumn(\"account_creation_timestamp\", unix_timestamp(\"account_creation_date\"))\n",
    "transaction_df = transaction_df.withColumn(\"transaction_timestamp\", unix_timestamp(\"transaction_date\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "491dd84b-40a3-46c6-90ba-e43537a5ab5b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCols=[\"payment_method\", \"location\"], outputCols=[\"payment_method_encoded\", \"location_encoded\"])\n",
    "transaction_df = indexer.fit(transaction_df).transform(transaction_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "205e6bbf-9926-4a99-a33d-02ad6bfb2f48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|transaction_id|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|   location|fraud_label|transaction_timestamp|payment_method_encoded|location_encoded|          features|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|           101|      1|            1200.0|2023-09-01 00:00:00|2024-09-21 10:00:00|   Credit Card|   New York|          0|           1693526400|                   0.0|             3.0|[1200.0,101.0,1.0]|\n",
      "|           102|      2|            250.75|2023-09-01 00:00:00|2024-09-21 11:00:00|    Debit Card|Los Angeles|          0|           1693526400|                   1.0|             2.0|[250.75,102.0,2.0]|\n",
      "|           103|      3|             500.0|2023-09-01 00:00:00|2024-09-21 12:00:00|   Credit Card|    Chicago|          0|           1693526400|                   0.0|             0.0| [500.0,103.0,3.0]|\n",
      "|           104|      1|             750.0|2023-09-02 00:00:00|2024-09-21 09:00:00|        PayPal|   New York|          0|           1693612800|                   2.0|             3.0| [750.0,104.0,1.0]|\n",
      "|           105|      4|            1800.5|2023-09-02 00:00:00|2024-09-21 10:30:00|   Credit Card|    Houston|          1|           1693612800|                   0.0|             1.0|[1800.5,105.0,4.0]|\n",
      "|           106|      2|             100.0|2023-09-02 00:00:00|2024-09-21 12:00:00|    Debit Card|Los Angeles|          0|           1693612800|                   1.0|             2.0| [100.0,106.0,2.0]|\n",
      "|           107|      5|            3000.0|2023-09-03 00:00:00|2024-09-21 08:00:00|   Credit Card|    Phoenix|          1|           1693699200|                   0.0|             4.0|[3000.0,107.0,5.0]|\n",
      "|           108|      3|             650.0|2023-09-03 00:00:00|2024-09-21 10:00:00|        PayPal|    Chicago|          0|           1693699200|                   2.0|             0.0| [650.0,108.0,3.0]|\n",
      "|           109|      4|             200.0|2023-09-03 00:00:00|2024-09-21 12:00:00|    Debit Card|    Houston|          0|           1693699200|                   1.0|             1.0| [200.0,109.0,4.0]|\n",
      "|           110|      5|              50.0|2023-09-04 00:00:00|2024-09-21 09:30:00|   Credit Card|    Phoenix|          0|           1693785600|                   0.0|             4.0|  [50.0,110.0,5.0]|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|transaction_id|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|   location|fraud_label|transaction_timestamp|payment_method_encoded|location_encoded|          features|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|           101|      1|            1200.0|2023-09-01 00:00:00|2024-09-21 10:00:00|   Credit Card|   New York|          0|           1693526400|                   0.0|             3.0|[1200.0,101.0,1.0]|\n",
      "|           102|      2|            250.75|2023-09-01 00:00:00|2024-09-21 11:00:00|    Debit Card|Los Angeles|          0|           1693526400|                   1.0|             2.0|[250.75,102.0,2.0]|\n",
      "|           104|      1|             750.0|2023-09-02 00:00:00|2024-09-21 09:00:00|        PayPal|   New York|          0|           1693612800|                   2.0|             3.0| [750.0,104.0,1.0]|\n",
      "|           105|      4|            1800.5|2023-09-02 00:00:00|2024-09-21 10:30:00|   Credit Card|    Houston|          1|           1693612800|                   0.0|             1.0|[1800.5,105.0,4.0]|\n",
      "|           106|      2|             100.0|2023-09-02 00:00:00|2024-09-21 12:00:00|    Debit Card|Los Angeles|          0|           1693612800|                   1.0|             2.0| [100.0,106.0,2.0]|\n",
      "|           108|      3|             650.0|2023-09-03 00:00:00|2024-09-21 10:00:00|        PayPal|    Chicago|          0|           1693699200|                   2.0|             0.0| [650.0,108.0,3.0]|\n",
      "|           110|      5|              50.0|2023-09-04 00:00:00|2024-09-21 09:30:00|   Credit Card|    Phoenix|          0|           1693785600|                   0.0|             4.0|  [50.0,110.0,5.0]|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|transaction_id|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|location|fraud_label|transaction_timestamp|payment_method_encoded|location_encoded|          features|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "|           103|      3|             500.0|2023-09-01 00:00:00|2024-09-21 12:00:00|   Credit Card| Chicago|          0|           1693526400|                   0.0|             0.0| [500.0,103.0,3.0]|\n",
      "|           107|      5|            3000.0|2023-09-03 00:00:00|2024-09-21 08:00:00|   Credit Card| Phoenix|          1|           1693699200|                   0.0|             4.0|[3000.0,107.0,5.0]|\n",
      "|           109|      4|             200.0|2023-09-03 00:00:00|2024-09-21 12:00:00|    Debit Card| Houston|          0|           1693699200|                   1.0|             1.0| [200.0,109.0,4.0]|\n",
      "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------------------+----------------------+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Assemble the feature vector\n",
    "feature_cols = ['transaction_amount', 'transaction_id', 'user_id']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "\n",
    "# Create labeled dataset\n",
    "labeled_data = assembler.transform(transaction_df)\n",
    "labeled_data.show()\n",
    "\n",
    "# Split the data\n",
    "train_df, test_df = labeled_data.randomSplit([0.8, 0.2], seed=42)\n",
    "train_df.show()\n",
    "test_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "de0b453a-a61d-4438-8d3f-79899dd4af21",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------+----------+\n",
      "|          features|fraud_label|prediction|\n",
      "+------------------+-----------+----------+\n",
      "| [500.0,103.0,3.0]|          0|       0.0|\n",
      "|[3000.0,107.0,5.0]|          1|       1.0|\n",
      "| [200.0,109.0,4.0]|          0|       0.0|\n",
      "+------------------+-----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model Training\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression(featuresCol='features', labelCol='fraud_label')\n",
    "lr_model = lr.fit(train_df)\n",
    "\n",
    "# Evaluate on test set\n",
    "test_results = lr_model.transform(test_df)\n",
    "test_results.select(\"features\", \"fraud_label\", \"prediction\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ad90097c-1511-43a6-9358-f680f27f6897",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started...\n"
     ]
    }
   ],
   "source": [
    "#Deploying the Model\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType, TimestampType,IntegerType,DoubleType\n",
    "# Define schema for transaction data\n",
    "transaction_schema = StructType([\n",
    "    StructField(\"transaction_id\", IntegerType(), True),\n",
    "    StructField(\"user_id\", IntegerType(), True),\n",
    "    StructField(\"transaction_amount\", DoubleType(), True),\n",
    "    StructField(\"transaction_date\", StringType(), True),\n",
    "    StructField(\"transaction_time\", StringType(), True),\n",
    "    StructField(\"payment_method\", StringType(), True),\n",
    "    StructField(\"location\", StringType(), True),\n",
    "    StructField(\"fraud_label\", IntegerType(), True)\n",
    "    \n",
    "])\n",
    "\n",
    "# Reading transaction data from streaming CSV\n",
    "streaming_df = spark.readStream \\\n",
    "    .schema(transaction_schema) \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .csv(\"dbfs:/FileStore/shared_uploads/varshinie.1006@gmail.com/transaction_fact.csv\")\n",
    "\n",
    "\n",
    "# Transform the streaming data similar to the training data\n",
    "streaming_features = assembler.transform(streaming_df)\n",
    "\n",
    "# Use the model to predict fraud in real-time\n",
    "predictions = lr_model.transform(streaming_features)\n",
    "\n",
    "# Write results to a sink (e.g., console, database)\n",
    "predictions.writeStream.format(\"console\").start()\n",
    "print(\"started...\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Project1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
