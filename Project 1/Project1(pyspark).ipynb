{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw8K4hsLJ3qb",
        "outputId": "1357433c-11d5-488c-d072-7612457deea8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=8447779df7ca664d5ac9e5c41b03446107fb9ebe5dc85e58cdb49da3952047d3\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8OllOR3IGBDO",
        "outputId": "9ad26f88-0f14-4589-a0d4-d655835012f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+-------+---------+-------------------+-----------+---------------------+\n",
            "|user_id|user_name|         user_email|   location|account_creation_date|\n",
            "+-------+---------+-------------------+-----------+---------------------+\n",
            "|      1|    Alice|  alice@example.com|   New York|           2020-01-15|\n",
            "|      2|      Bob|    bob@example.com|Los Angeles|           2020-03-22|\n",
            "|      3|  Charlie|charlie@example.com|    Chicago|           2021-05-10|\n",
            "|      4|    David|  david@example.com|    Houston|           2019-07-30|\n",
            "|      5|      Eva|    eva@example.com|    Phoenix|           2022-08-14|\n",
            "+-------+---------+-------------------+-----------+---------------------+\n",
            "\n",
            "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+\n",
            "|transaction_id|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|   location|fraud_label|\n",
            "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+\n",
            "|           101|      1|            1200.0|2023-09-01 00:00:00|2024-09-12 10:00:00|   Credit Card|   New York|          0|\n",
            "|           102|      2|            250.75|2023-09-01 00:00:00|2024-09-12 11:00:00|    Debit Card|Los Angeles|          0|\n",
            "|           103|      3|             500.0|2023-09-01 00:00:00|2024-09-12 12:00:00|   Credit Card|    Chicago|          0|\n",
            "|           104|      1|             750.0|2023-09-02 00:00:00|2024-09-12 09:00:00|        PayPal|   New York|          0|\n",
            "|           105|      4|            1800.5|2023-09-02 00:00:00|2024-09-12 10:30:00|   Credit Card|    Houston|          1|\n",
            "|           106|      2|             100.0|2023-09-02 00:00:00|2024-09-12 12:00:00|    Debit Card|Los Angeles|          0|\n",
            "|           107|      5|            3000.0|2023-09-03 00:00:00|2024-09-12 08:00:00|   Credit Card|    Phoenix|          1|\n",
            "|           108|      3|             650.0|2023-09-03 00:00:00|2024-09-12 10:00:00|        PayPal|    Chicago|          0|\n",
            "|           109|      4|             200.0|2023-09-03 00:00:00|2024-09-12 12:00:00|    Debit Card|    Houston|          0|\n",
            "|           110|      5|              50.0|2023-09-04 00:00:00|2024-09-12 09:30:00|   Credit Card|    Phoenix|          0|\n",
            "+--------------+-------+------------------+-------------------+-------------------+--------------+-----------+-----------+\n",
            "\n",
            "+-------+--------------------+----------+\n",
            "|rule_id|         description|risk_score|\n",
            "+-------+--------------------+----------+\n",
            "|      1|High transaction ...|         8|\n",
            "|      2|   Location mismatch|         6|\n",
            "|      3|Suspicious paymen...|         7|\n",
            "+-------+--------------------+----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
        "\n",
        "# Load data from CSV files into Spark DataFrames\n",
        "user_df = spark.read.csv(\"/content/sample_data/user_dim.csv\", header=True, inferSchema=True)\n",
        "transaction_df = spark.read.csv(\"/content/sample_data/transaction_fact.csv\", header=True, inferSchema=True)\n",
        "fraud_indicators_df = spark.read.csv(\"/content/sample_data/fraud_indicators.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Show data to verify\n",
        "user_df.show()\n",
        "transaction_df.show()\n",
        "fraud_indicators_df.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Yr3EbKU3R3",
        "outputId": "d6f8be28-1e1d-4e9a-f2b7-ebb09eb3ad75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------+-----------------+--------+---------------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+\n",
            "|transaction_id|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|location|fraud_label|user_name|       user_email|location|account_creation_date|user_id|transaction_amount|   transaction_date|   transaction_time|payment_method|location|fraud_label|\n",
            "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------+-----------------+--------+---------------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+\n",
            "|           101|      1|            1200.0|2023-09-01 00:00:00|2024-09-12 10:00:00|   Credit Card|New York|          0|    Alice|alice@example.com|New York|           2020-01-15|      1|            1200.0|2023-09-01 00:00:00|2024-09-12 10:00:00|   Credit Card|New York|          0|\n",
            "|           105|      4|            1800.5|2023-09-02 00:00:00|2024-09-12 10:30:00|   Credit Card| Houston|          1|    David|david@example.com| Houston|           2019-07-30|      4|            1800.5|2023-09-02 00:00:00|2024-09-12 10:30:00|   Credit Card| Houston|          1|\n",
            "|           107|      5|            3000.0|2023-09-03 00:00:00|2024-09-12 08:00:00|   Credit Card| Phoenix|          1|      Eva|  eva@example.com| Phoenix|           2022-08-14|      5|            3000.0|2023-09-03 00:00:00|2024-09-12 08:00:00|   Credit Card| Phoenix|          1|\n",
            "+--------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+---------+-----------------+--------+---------------------+-------+------------------+-------------------+-------------------+--------------+--------+-----------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Create Spark session\n",
        "spark = SparkSession.builder.appName(\"FraudDetection\").getOrCreate()\n",
        "\n",
        "# Load static data from CSV files\n",
        "transaction_df = spark.read.csv(\"/content/sample_data/transaction_fact.csv\", header=True, inferSchema=True)\n",
        "user_df = spark.read.csv(\"/content/sample_data/user_dim.csv\", header=True, inferSchema=True)\n",
        "fraud_indicators_df = spark.read.csv(\"/content/sample_data/fraud_indicators.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Detect anomalies from static data\n",
        "anomalies = transaction_df.filter(\n",
        "    (col(\"transaction_amount\") > 1000) |\n",
        "    (col(\"location\") != col(\"location\"))\n",
        ")\n",
        "\n",
        "# join with user_df and transaction_df to enrich data\n",
        "enriched_anomalies = anomalies.join(user_df, \"user_id\", \"left\") \\\n",
        "                               .join(transaction_df, \"transaction_id\", \"left\")\n",
        "\n",
        "# Show results\n",
        "enriched_anomalies.show()\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
