{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLO6TLCLcYlC",
        "outputId": "22e5fce4-9ddc-4b6a-cc5a-11d80f31d147"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.2.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.2-py2.py3-none-any.whl size=317812365 sha256=34af4d3a5273a50dc4a8975326931c793cf8db9085f08e905ba877963649962a\n",
            "  Stored in directory: /root/.cache/pip/wheels/34/34/bd/03944534c44b677cd5859f248090daa9fb27b3c8f8e5f49574\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.2\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5yujRPDTPU1",
        "outputId": "89a0a156-780a-45ff-eb90-3f1e5969c307"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streaming stared...\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, IntegerType, TimestampType\n",
        "\n",
        "# Start Spark session\n",
        "spark = SparkSession.builder.appName(\"FraudDetectionStreaming\").getOrCreate()\n",
        "\n",
        "# Define schema for the transaction data\n",
        "schema = StructType([\n",
        "    StructField(\"TransactionID\", IntegerType(), True),\n",
        "    StructField(\"UserID\", IntegerType(), True),\n",
        "    StructField(\"TransactionAmount\", DoubleType(), True),\n",
        "    StructField(\"TransactionLocation\", StringType(), True),\n",
        "    StructField(\"TransactionTime\", TimestampType(), True),\n",
        "    StructField(\"PaymentMethod\", StringType(), True),\n",
        "    StructField(\"TransactionStatus\", StringType(), True),\n",
        "    StructField(\"FraudLabel\", IntegerType(), True)\n",
        "])\n",
        "\n",
        "# Reading streaming source\n",
        "streaming_df = spark.readStream.schema(schema).csv(\"/content/sample_data/transaction.csv\")\n",
        "\n",
        "# Process the stream \n",
        "query = streaming_df.writeStream.outputMode(\"append\").format(\"console\").start()\n",
        "\n",
        "print(\"Streaming stared...\")\n",
        "#query.awaitTermination()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jCpwFvlsT83e",
        "outputId": "5809d5b5-3791-4406-9fe2-8ca9a39d3350"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Anomaly detection started...\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Define threshold for flagging large transactions\n",
        "large_transaction_threshold = 1000.0\n",
        "\n",
        "# Filter transactions that exceed the threshold and are flagged as fraud\n",
        "anomalous_transactions = streaming_df.filter(\n",
        "    (col(\"TransactionAmount\") > large_transaction_threshold) |\n",
        "    (col(\"FraudLabel\") == 1)\n",
        ")\n",
        "\n",
        "# Output anomalous transactions to console \n",
        "anomaly_query = anomalous_transactions.writeStream.outputMode(\"append\").format(\"console\").start()\n",
        "\n",
        "print(\"Anomaly detection started...\")\n",
        "#anomaly_query.awaitTermination()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
